{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "288px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "04_LinearModels_Evaluation.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atycxuXjYMKU"
      },
      "source": [
        "# Celdas preparatorias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v5m__QsYMKW"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"04_ModelEvaluation\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "\n",
        "# Ignore useless warnings (see SciPy issue #5998)\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB3D-uS1YMKX"
      },
      "source": [
        "# Obtención de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTSXl66XYMKX"
      },
      "source": [
        "Para estudiar el tema de la evaluación de modelos, vamos a obtener los datos de la última vez."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2klN5T0lYMKX"
      },
      "source": [
        "AIRLINE_PATH = \"datasets/airline_fatalities\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i50XAvDYMKY",
        "outputId": "7e7ea6c6-a6a0-4b6e-e36c-0109223cf31b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "        \n",
        "    import tarfile\n",
        "\n",
        "    DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/IAI-UNSAM/datasets/master/\"\n",
        "    AIRLINE_URL = DOWNLOAD_ROOT + \"airline_fatalities/Data-Table\\ 1.csv\"\n",
        "\n",
        "    def fetch_fatalities(AIRLINE_URL=AIRLINE_URL, airline_path=AIRLINE_PATH):\n",
        "        os.makedirs(airline_path, exist_ok=True)\n",
        "        !wget {AIRLINE_URL} -P {airline_path}\n",
        "\n",
        "    # Corramos la función\n",
        "    fetch_fatalities()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-31 22:25:02--  https://raw.githubusercontent.com/IAI-UNSAM/datasets/master/airline_fatalities/Data-Table%201.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 501 [text/plain]\n",
            "Saving to: ‘datasets/airline_fatalities/Data-Table 1.csv’\n",
            "\n",
            "Data-Table 1.csv    100%[===================>]     501  --.-KB/s    in 0s      \n",
            "\n",
            "2021-03-31 22:25:02 (25.5 MB/s) - ‘datasets/airline_fatalities/Data-Table 1.csv’ saved [501/501]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUI2OSXwYMKY"
      },
      "source": [
        "year, acc, deaths, rate = np.loadtxt(os.path.join(AIRLINE_PATH, 'Data-Table 1.csv'), delimiter=',', skiprows=2, unpack=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWmAu867YMKZ",
        "outputId": "2bb0ed04-7121-49e3-949b-844c4ab10787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "fig= plt.figure(figsize=(9, 6))\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "\n",
        "l0, = ax.plot(year, rate, 'o-', mfc='None', ms=10, mew=1, color='g', label='Muertes / 100 mill. kms')\n",
        "\n",
        "ax.set_xlabel('Año', fontsize=16)\n",
        "ax.set_ylabel('Tasa', fontsize=16)\n",
        "\n",
        "ax.legend(loc=0, fontsize=16)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6c96f95a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2Z-yaypYMKZ"
      },
      "source": [
        "rate.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxas9fwrYMKa"
      },
      "source": [
        "La semana pasada ajustamos un modelo lineal simple de la forma:\n",
        "\n",
        "$$\n",
        "y(\\mathbf{x}, \\boldsymbol{\\omega}) = \\omega_0 + \\omega_1 \\mathbf{x}\\;\\;.\n",
        "$$\n",
        "\n",
        "Volvamos a hacerlo y veamos la curva que se obtiene."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MWhEg7FYMKa"
      },
      "source": [
        "X = year.reshape(-1, 1)\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZL1zwD1YMKa"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Le damos forma a los datos para prepararlos para sklearn\n",
        "X = year.reshape(-1, 1)\n",
        "t = rate.reshape(-1, 1)\n",
        "\n",
        "# Ajusta el modelo\n",
        "lr = LinearRegression()\n",
        "lr.fit(X, t)\n",
        "\n",
        "# Calcula predicciones y los residuos\n",
        "y = lr.predict(X)\n",
        "res = t - y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfr5GyaXYMKb"
      },
      "source": [
        "fig= plt.figure(figsize=(9, 6))\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "l0, = ax.plot(year, rate, 'o-', mfc='None', ms=10, mew=1, color='g', label='Muertes / 100 mill. kms')\n",
        "l1, = ax.plot(year, y, 'o-r', lw=3, alpha=0.8)\n",
        "ax.set_xlabel('Año', fontsize=16)\n",
        "ax.set_ylabel('Tasa', fontsize=16)\n",
        "\n",
        "ax.legend(loc=0, fontsize=16)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO1vzyQzYMKb"
      },
      "source": [
        "También calculamos los residuos $\\left\\{r_i\\right\\}$, con $i = 1, \\ldots, N$, definidos como la diferencia entre los valores medidos y la predicción del modelo:\n",
        "\n",
        "$$\n",
        "r_i = t_i - y(\\mathbf{x}_i, \\boldsymbol{\\omega})\\;\\;.\n",
        "$$\n",
        "\n",
        "Una de las cosas para las que usamos los residuos fue para estimar la varianza de los términos de error $\\epsilon_i$ [**Nota**: recordemos que suponemos $\\epsilon_i \\sim N(0, \\sigma^2)$]:\n",
        "\n",
        "$$\n",
        "\\widehat{\\text{var}(\\epsilon)} = \\widehat{\\sigma}^2 = \\frac{1}{N-2}\\sum_{i=1}^N r_i^2\\;\\;.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0e0BIaMYMKb"
      },
      "source": [
        "Ese valor nos sirvió también para hacer inferencia sobre el parámetro $\\omega_1$, y decidir si es significativamente diferente de cero, y para estimar el error que tendrán las predicciones que hagamos con el modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HufdQaabYMKc"
      },
      "source": [
        "Pero también podemos usar los residuos para evaluar la performance del modelo de muchas maneras diferentes. Esto se pude hacer para el modelo lineal simple, y es lo que vamos a ver ahora, pero es particularmente útil para el caso del modelo lineal múltiple, donde va a ser más difícil plotear directamente $y(\\mathbf{x}, \\mathbf{w})$. \n",
        "\n",
        "Pero primero tenemos que ver el concepto de *leverage*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j6GZnAxYMKc"
      },
      "source": [
        "yamano = lr.intercept_[0] + lr.coef_[0] * X\n",
        "np.allclose(y, yamano)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H72Bxx1yYMKc"
      },
      "source": [
        "# Evaluación de los modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8wDroRXYMKc"
      },
      "source": [
        "## Leverage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2NobSQSYMKd"
      },
      "source": [
        "El concepto de *leverage* o palanca es da gran utilidad para estudiar el funcionamiento del modelo y la influencia de los datos.\n",
        "\n",
        "Se puede mostrar que el valor predicho de la variable $t$ para un valor del *feature* $x_i$ puede expresarse como una combinación lineal de *todos* los labels.\n",
        "\n",
        "$$\n",
        "y_i = \\hat{\\omega_0} + \\hat{\\omega_1} x_i = \\sum_{k=1}^N h_{ik} t_k\\;\\;,\n",
        "$$\n",
        "donde $h_{ik}$ se define:\n",
        "\n",
        "$$\n",
        "h_{ik}: = \\frac{1}{N} + \\frac{\\left(x_i - \\bar{x}\\right)\\left(x_k - \\bar{x}\\right)}{S_{xx}}\\;\\;,\n",
        "$$\n",
        "\n",
        "con, recordemos, \n",
        "$$\n",
        "\\bar{x} = \\frac{1}{N} \\sum_{i=1}^N x_i\n",
        "$$\n",
        "y\n",
        "$$\n",
        "S_{xx} = \\sum_{i=1}^N \\left(x_i - \\bar{x}\\right)^2\\;\\;.\n",
        "$$\n",
        "\n",
        "Es decir, la predicción es una combinación lineal de los valores observados, pesada por el elemento $h_{ik}$ (de la matriz sombrero / hat). Ese valor $h_{ik}$ nos dice cuánto pesa cada medición $k$ en la predicción del valor $y_i$.\n",
        "\n",
        "Let's compute this for our data, knowing that $\\bar{x}=0$, because of the preprocessing (alright, I'll write the whole thing so you can use it in other cases!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ndPvN3EYMKd"
      },
      "source": [
        "# this works in multi dimensions\n",
        "if 'google.colab' in sys.modules:\n",
        "        \n",
        "    from scipy.linalg import cho_factor, cho_solve\n",
        "\n",
        "    def hat_matrix(X, include_bias=True):\n",
        "        \"\"\"\n",
        "        Compute hat matrix for design matrix X.\n",
        "\n",
        "        :param np.array X: design matrix of dimensions (n x d), \n",
        "        where n is the number of observations and d is the number of\n",
        "        features.\n",
        "        :param bool include_bias: if True (default), then include a bias column, \n",
        "        in design matrix X (i.e. a column of ones - acts as an\n",
        "        intercept term in a linear model).\n",
        "        \"\"\"\n",
        "        if include_bias:\n",
        "            X = np.hstack([np.ones([len(X), 1]), X])\n",
        "\n",
        "        A = np.matmul(X.T, X)\n",
        "\n",
        "        LL = cho_factor(A)\n",
        "        return np.matmul(X, cho_solve(LL, X.T))\n",
        "else: \n",
        "    from utils import hat_matrix\n",
        "    \n",
        "# Define HAT matrix, whose diagonal are the leverage values\n",
        "h = hat_matrix(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waNt-4MDYMKe"
      },
      "source": [
        "Esta matriz nos dice cómo influye cada observación en la predicción de cualquier otra observación.\n",
        "\n",
        "Podemos graficar la influencia que cada observación tiene sobre otras (tengan en cuenta que todo esto es independiente de $t$; solo tiene en cuenta los valores de la variable predictora)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stoc74PXYMKe"
      },
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "\n",
        "# Elijo que filas de la matriz voy a plotear.\n",
        "indices_to_plot = [0, 11, -1]\n",
        "\n",
        "for c,i in enumerate(indices_to_plot):\n",
        "    plt.plot(X[:, 0], h[i], 'o', ms=10, mfc='None', label=i, color='C{}'.format(c))\n",
        "    plt.plot(X[i, 0], h[i, i], 'o', ms=10, color='C{}'.format(c))\n",
        "plt.xlabel('Año', fontsize=16)\n",
        "plt.ylabel('Leverage', fontsize=16)\n",
        "plt.legend(loc=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwP-Ldw_YMKe"
      },
      "source": [
        "En particular, la diagonal de la matriz sombrero, que contiene el nivel de influencia de cada observación sobre su propia predicción, se conoce como *leverage* o palanca de esa observación.\n",
        "\n",
        "Podemos graficarla en función de la variable predictora:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-IQLHneYMKf"
      },
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "\n",
        "# Elijo que filas de la matriz voy a plotear.\n",
        "plt.plot(X, np.diag(h), 'o', ms=10, mfc='None', label=i, color='C{}'.format(c))\n",
        "plt.xlabel('Año', fontsize=16)\n",
        "plt.ylabel('Leverage', fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0QslsghYMKf"
      },
      "source": [
        "Como es razonable esperar a partir de la ecuación que define la matriz sombrero (y a partir de la intuición), las observaciones que se encuentran cerca se afectan más fuertemente. Es razonable pensar que se toma en cuenta la influencia local con mayor intensidad que la influencia general o global.\n",
        "\n",
        "Esto será también el puntapié para entender métodos de *kernel*, que vamos a discutir de acá a unas semanas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrKMLqYYYMKf"
      },
      "source": [
        "Antes de pasar al tema de residuos, mencionemos una propiedad más de los *leverage*:\n",
        "\n",
        "$$\n",
        "\\sum_{i=1}^N h_{ii} = 2\\;\\;.\n",
        "$$\n",
        "\n",
        "Más en general, la suma de los *leverage* debe ser igual a la dimensión del vector de parámetros, $\\boldsymbol{\\omega}$, como puede verse de la definición de la matrix sombrero para el caso multidimensional (implementada en el modulo `utils`):\n",
        "\n",
        "$$\n",
        "H = \\boldsymbol{\\Phi}\\;(\\boldsymbol{\\Phi}^T \\boldsymbol{\\Phi})^{-1} \\boldsymbol{\\Phi}^T\\;\\;,\n",
        "$$\n",
        "\n",
        "donde $\\boldsymbol{\\Phi}$ es la matrix de diseño que vimos la última clase, y tiene dimensiones $(N x D)$, donde $D$ es el número de funciones de base del modelo lineal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjrRZnn4YMKg"
      },
      "source": [
        "## Residuos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ39-z0lYMKg"
      },
      "source": [
        "### Residual plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5yzE2r7YMKg"
      },
      "source": [
        "Ahora sí, volvamos a los residuos. \n",
        "\n",
        "Lo primero que uno puede hacer es graficarlos en función de la variable descriptiva, $x$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stEMDdE_YMKg"
      },
      "source": [
        "# Plot residuals against feature $x_1$.\n",
        "fig = plt.figure(figsize=(8,5))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot(X, res, 'ok', mfc='None', ms=10, color='g')\n",
        "\n",
        "ax.axhline(0, color='r', ls=':')\n",
        "# ax.set_xlabel('Predicción / y')\n",
        "ax.set_xlabel('Año')\n",
        "ax.set_ylabel('Residuos')\n",
        "\n",
        "# Add mean on each axis\n",
        "xmean = X.mean()\n",
        "ax.axvline(xmean, color='r', ls=':')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvh3ummRYMKh"
      },
      "source": [
        "Las ecuaciones normales nos garantizaban dos propiedades de los residuos:\n",
        "\n",
        "$$\n",
        "\\sum_{i=1}^N r_i = 0\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\rho(\\mathbf{x}, \\mathbf{r}) = 0\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xGG86UgYMKi"
      },
      "source": [
        "print('Suma de los residuos {:.16f}'.format(res.sum()))\n",
        "print('$rho(X, res)$ = {:.16f}'.format(np.corrcoef(X.T, res.T)[0, 1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezmpGLPoYMKi"
      },
      "source": [
        "De lo que dijimos arriba, se puede desprender, de manera informal, que $\\mathbb{E}(r_i) = 0$, para todo $i = 1, \\ldots, N$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLMtIULXYMKj"
      },
      "source": [
        "**EJEMPLOS DE PLOTS MALOS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsliKquNYMKj"
      },
      "source": [
        "### Varianza de los residuos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNTcOfK6YMKj"
      },
      "source": [
        "Además, es interesante ver qué expresión tiene la variaza de los residuos:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE_BVgbDYMKj"
      },
      "source": [
        "$$\\mathrm{var}(r_i) = \\sigma^2 (1 - h_{ii})\\;\\;\\text{, donde}$$\n",
        "\n",
        "$$h_{ii} = \\frac{1}{N} + \\frac{X_i - \\bar{X}}{S_{xx}}\\text{ es el leverage}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeXRAacJYMKj"
      },
      "source": [
        "De la definición de *leverage* podemos ver que los valores están acotados, de manera que nunca valen más que uno (de manera que la varianza nunca puede ser negativa).\n",
        "\n",
        "Lo que resulta interesante es que una observación que tenga mucho leverage tendrá un residuo cuya varianza es muy inferior al valor de la varianza de su término de error. Esta observación tira del modelo para acercarlo a ella, por lo que genera esa reducción de la varianza."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj3dVoQcYMKk"
      },
      "source": [
        "Para ver esto, nada como datos sintéticos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "b21JvyYuYMKk"
      },
      "source": [
        "# defino funciones útiles\n",
        "def make_default_dataset(real_process, sigma=0.5, high_leverage=None, random_seed=20210331):\n",
        "    # Fijo seed\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    # Defino vector de x\n",
        "    x = np.random.rand(20)\n",
        "\n",
        "    # Por si quiero otra nube de puntos\n",
        "#     x2 = np.random.rand(4) + 2.5\n",
        "#     x = np.concatenate([x, x2])\n",
        "        \n",
        "    x = np.sort(x)\n",
        "\n",
        "    # Agrego un punto con mucha palanca\n",
        "    if high_leverage is not None:\n",
        "        high_leverage_x = np.array(high_leverage)\n",
        "        x = np.append(x, high_leverage_x)\n",
        "    \n",
        "    x_plot = np.linspace(x.min(), x.max(), 100).reshape(-1, 1)\n",
        "\n",
        "    # Error\n",
        "    t = real_process(x) + np.random.randn(len(x)) * sigma\n",
        "    \n",
        "    return x, t, x_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChVj_JT5YMKk"
      },
      "source": [
        "def ground_truth(x):\n",
        "    return 3*x + 4 #+ 0.1*x**2\n",
        "\n",
        "# Creo los datos\n",
        "x, t, x_plot = make_default_dataset(ground_truth, high_leverage=3.0)\n",
        "\n",
        "# Plot datos y gt\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(x, t, 'o', ms=10)\n",
        "plt.plot(x_plot, ground_truth(x_plot), '-', color='0.5', label='Proceso real')\n",
        "plt.xlabel('X', fontsize=16)\n",
        "plt.ylabel('t', fontsize=16)\n",
        "\n",
        "# Ajusto y ploteo ajuste\n",
        "lr = LinearRegression()\n",
        "lr.fit(x.reshape(-1, 1), t)\n",
        "plt.plot(x_plot, lr.predict(x_plot), '-r', lw=4, alpha=0.5, label='Ajuste')\n",
        "plt.legend(loc=0, fontsize=16)\n",
        "\n",
        "# Calculo los residuos\n",
        "res = t - lr.predict(x.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQEpf0EfYMKl"
      },
      "source": [
        "print(lr.intercept_, lr.coef_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16OCa0rxYMKl"
      },
      "source": [
        "Ahora repitamos el proceso de generación de datos (dejando fijas las variables $X$) y calculemos el mejor ajuste y los residuos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZHBRpAKYMKl"
      },
      "source": [
        "nsimu=1000\n",
        "\n",
        "res_ = np.empty((nsimu, len(x)))\n",
        "t_ = np.empty((nsimu, len(x)))\n",
        "sigma = 0.5\n",
        "for i in range(nsimu):\n",
        "    # Nuevo dataset\n",
        "    t_new = ground_truth(x) + np.random.randn(len(x)) * sigma\n",
        "    \n",
        "    t_[i] = t_new\n",
        "    # Ajusta y predice\n",
        "    lr.fit(x.reshape(-1, 1), t_new)\n",
        "    y = lr.predict(x.reshape(-1, 1))\n",
        "    \n",
        "    # Calcula residuos y guarda\n",
        "    res_[i] = t_new - y\n",
        "    \n",
        "# Ordenemos los residuos por valor de x\n",
        "res_ = res_[:, np.argsort(x)]\n",
        "x_ = np.sort(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC3OI_oMYMKl"
      },
      "source": [
        "# Plot datos y gt\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(x, t, 'o', ms=10)\n",
        "plt.plot(x, t_new, 'o', ms=10)\n",
        "plt.plot(x_plot, ground_truth(x_plot), '-', color='0.5', label='Proceso real')\n",
        "plt.xlabel('X', fontsize=16)\n",
        "plt.ylabel('t', fontsize=16)\n",
        "\n",
        "# Ajusto y ploteo ajuste\n",
        "# lr = LinearRegression()\n",
        "# lr.fit(x.reshape(-1, 1), t)\n",
        "# plt.plot(x_plot, lr.predict(x_plot), '-r', lw=4, alpha=0.5, label='Ajuste')\n",
        "# plt.legend(loc=0, fontsize=16)\n",
        "\n",
        "# Calculo los residuos\n",
        "# res = t - lr.predict(x.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALtZLAX5YMKm"
      },
      "source": [
        "Ahora hagamos histogramas de los residuos para distintos valores de $X$. Recordemos que, como nosotros definimos el proceso real, sabemos con certeza que $\\sigma^2 = (0.5)^2$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMev8SgnYMKm"
      },
      "source": [
        "# Veamos la dispersión de los datos entorno de la media del valor real\n",
        "np.std(t_ - ground_truth(x), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "G-2upe0IYMKm"
      },
      "source": [
        "indices_to_plot = [0, 11, -1]\n",
        "\n",
        "plt.figure(figsize=(9, 6))\n",
        "for i in indices_to_plot:\n",
        "    plt.hist(res_[:, i], 25, label='X = {:.1f} (std(res) = {:.2f})'.format(x_[i], res_[:, i].std()), histtype='step', lw=3)\n",
        "plt.xlabel('Residuals of observation X')\n",
        "plt.legend(loc=0, fontsize=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX9N_LwlYMKm"
      },
      "source": [
        "### *Leverage* vs. Residuals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3bF8nArYMKn"
      },
      "source": [
        "Un plot muy relevante es el de los valores de *leverage* en función de los residuos.\n",
        "\n",
        "Sigamos por ahora con nuestros datos sintéticos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4Xlkxp5YMKn"
      },
      "source": [
        "# Calculamos leverage para los datos sintéticos\n",
        "h = np.diag(hat_matrix(x.reshape(-1, 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr1Tt1lSYMKn"
      },
      "source": [
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(h, res, 'o', ms=10)\n",
        "plt.axhline(0, color='r', ls=':')\n",
        "# plt.gca().set_xscale('log')\n",
        "\n",
        "plt.ylabel('Residuals', fontsize=16)\n",
        "plt.xlabel('Leverage', fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c13Zfg2RYMKn"
      },
      "source": [
        "Otra forma de ver los *leverages* es con un boxplot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1fxPvJ-YMKn"
      },
      "source": [
        "fig = plt.figure(figsize=(9, 6))\n",
        "\n",
        "ax = fig.add_subplot(121)\n",
        "bp = ax.boxplot(h)\n",
        "ax2 = fig.add_subplot(122)\n",
        "hp = ax2.hist(h, histtype='step', color='k', lw=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q8b5SuBYMKo"
      },
      "source": [
        "### Residuos estandarizados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT-63AuiYMKo"
      },
      "source": [
        "Una pequeña precisión que puede hacerse es definir los residuos estandarizados, en los que dividimos a cada residuo por la raíz cuadrada de varianza esperada.\n",
        "\n",
        "$$\n",
        "R_i = \\frac{r_i}{\\sqrt{\\widehat{\\mathrm{var}}(r_i)}} = \\frac{r_i}{\\sqrt{\\widehat{\\sigma}^2 (1 - h_{ii})}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt36tJfyYMKo"
      },
      "source": [
        "sigma2hat = np.sum(res**2)/(len(res) - 2)\n",
        "stres = res / np.sqrt(sigma2hat * (1 - h))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hflMeuYYMKo"
      },
      "source": [
        "Los plots que mencionamos arriba pueden volver a hacerse con los resiudos estandarizados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zckHr3KJYMKo"
      },
      "source": [
        "plt.figure(figsize=(9, 6))\n",
        "plt.semilogx(h, stres, 'o', ms=10)\n",
        "plt.axhline(0, color='r', ls=':')\n",
        "# plt.gca().set_xscale('log')\n",
        "\n",
        "plt.ylabel('Residuos Estandarizados', fontsize=16)\n",
        "plt.xlabel('Leverage', fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPRmCCd8YMKp"
      },
      "source": [
        "## Outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYHTj8M-YMKp"
      },
      "source": [
        "Uno de los tests importantes a hacer es el de puntos atípicos (*outliers*). Si por alguna razón los datos tienen algún valor que no proviene del proceso real, eso puede modificar  el resultado del ajuste y, en particular, sesgarlo fuertemente.\n",
        "\n",
        "Por ejemplo, agarremos los datos sintéticos y hagamos que uno de los puntos se vuelva un outlier, poniendo un valor a mano. Para que el efecto sea claro, tenemos que hacerlo en un punto que tenga palanca. Veamos..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAaud6UtYMKp"
      },
      "source": [
        "x, t, x_plot = make_default_dataset(ground_truth, high_leverage=3.0)\n",
        "\n",
        "# Recompute leverage\n",
        "h = np.diag(hat_matrix(x.reshape(-1, 1)))\n",
        "\n",
        "# Define an outlier observation.\n",
        "t[-1] =10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlr4_MJkYMKp"
      },
      "source": [
        "# Plot datos y gt\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(x, t, 'o', ms=10)\n",
        "plt.plot(x_plot, ground_truth(x_plot), '-', color='0.5', label='Proceso real')\n",
        "plt.xlabel('X', fontsize=16)\n",
        "plt.ylabel('t', fontsize=16)\n",
        "\n",
        "# Ajusto y ploteo ajuste\n",
        "lr = LinearRegression()\n",
        "lr.fit(x.reshape(-1, 1), t)\n",
        "plt.plot(x_plot, lr.predict(x_plot), '-r', lw=4, alpha=0.5, label='Ajuste')\n",
        "plt.legend(loc=0, fontsize=16)\n",
        "\n",
        "# Calculo los residuos\n",
        "res = t - lr.predict(x.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMWqsKN3YMKp"
      },
      "source": [
        "Sin embargo, miren qué pasa si miramos el gráfico de leverage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNc1xbUPYMKq"
      },
      "source": [
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(h, res, 'o', ms=10)\n",
        "plt.axhline(0, color='r', ls=':')\n",
        "# plt.gca().set_xscale('log')\n",
        "\n",
        "plt.ylabel('Residuos', fontsize=16)\n",
        "plt.xlabel('Leverage', fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbD2Q-L-YMKq"
      },
      "source": [
        "plt.plot(x, res, 'or')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyXPLWyKYMKq"
      },
      "source": [
        "Si bien el outlier está bastante afuera, no llama mucho la atención. Es claro lo que pasa: el outlier ya arrastró la solución y entonces el residuo es relativamente pequeño para ese punto.\n",
        "\n",
        "**¿Y entonces? ¿Cómo hacemos? ¿Ideas? ¿Ideas que funcionen en muchas dimensiones?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf9xD4FXYMKq"
      },
      "source": [
        "### Validación Cruzada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Wi3Pb3vYMKq"
      },
      "source": [
        "Una posibilidad, es hacer uso de una herramienta que será central en la materia para detectar y evitar el sobre-ajuste (*overfitting*), que se llama validación cruzada (*cross-validation*). \n",
        "\n",
        "Acá la vamos a usar para detectar el punto que se escapa. De alguna forma, también se trata de sobreajuste, porque el modelo intenta agarrar todo el set de entrenamiento, en lugar de preocuparse por reproducir la tendencia general, acá dada por el proceso real (¡que por suerte acá conocemos!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n7c0GT2YMKr"
      },
      "source": [
        "La idea va a ser construir sub-sets de datos, a partir del set original, sacando un punto por vez. Es decir, se construyen $N$ conjuntos de $N-1$ datos, y se ajusta un modelo para cada uno de esos datos nuevos. Después, se compara la predicción que hace cada modelo para el punto que sacamos con la que hace el modelo ajustado a todos los datos.\n",
        "\n",
        "La intuición es que cuando saquemos el outlier que está infuyendo en el ajuste, la predicción cambiará rotundamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywAVljx3YMKr"
      },
      "source": [
        "Esto se llama *Leave-one-out cross-validation*, porque los puntos se van tomando de a uno. Hay muchos más sabores de validación cruzada, algunos de los cuales veremos más adelante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_9dn6GTYMKr"
      },
      "source": [
        "# Implementación de LOOCV en sklearn\n",
        "from sklearn.model_selection import LeaveOneOut, LeavePOut, cross_val_predict\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "# loo = LeavePOut(3)\n",
        "for train, test in loo.split(x):\n",
        "    print(train, test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkaSJCskYMKr"
      },
      "source": [
        "# Compute the predictions of Linear Regressor leaving each point out\n",
        "y_iout = cross_val_predict(lr, x.reshape(-1, 1), t, cv=loo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGaKHzJNYMKr"
      },
      "source": [
        "print(y_iout.shape, x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMFm0I-0YMKs"
      },
      "source": [
        "# pero para entenderlo, está bueno hacerlo a mnos, aunque sea una vez.\n",
        "y_iout_mano = np.empty_like(t)\n",
        "\n",
        "for i, [train, test] in enumerate(loo.split(x)):\n",
        "    x_i = x[train]\n",
        "    t_i = t[train]\n",
        "    \n",
        "    lr.fit(x_i.reshape(-1, 1), t_i)\n",
        "    y_ii = lr.predict(x[test].reshape(-1, 1))\n",
        "    \n",
        "    y_iout_mano[i] = y_ii"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z_l625gYMKs"
      },
      "source": [
        "np.allclose(y_iout, y_iout_mano)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIaaDl1tYMKs"
      },
      "source": [
        "lr.fit(x.reshape(-1, 1), t)\n",
        "y = lr.predict(x.reshape(-1, 1))\n",
        "plt.plot(x, (y - y_iout), 'or', ms=10, mfc='None')\n",
        "plt.xlabel('X', fontsize=16)\n",
        "plt.ylabel('$Y_i - Y_{i(i)}$')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WfzNNsqYMKs"
      },
      "source": [
        "Podemos ver que claramente el outlier salta a la vista.\n",
        "\n",
        "Para casos menos obvios, podemos definir un estadístico que se compara con alguna distribución razonable, pero no vamos a entrar en esos detalles ahora."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0eZj7diYMKt"
      },
      "source": [
        "### Relevancia de una observación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPotND-fYMKt"
      },
      "source": [
        "Obviamente, un outlier como el que vimos recién es una observación muy influyente, que determina fuertemente el resultado del ajuste.\n",
        "\n",
        "Pero si ese mismo outlier hubiera tenido menos palanca, la cosa hubiera sido diferente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCeCbsbcYMKt"
      },
      "source": [
        "#### Ejercicio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skQeEvaDYMKt"
      },
      "source": [
        "* Modifiquen la posición y el valor del outlier. Vean qué influencia tiene en cada caso.\n",
        "* Discutan qué combinación tiene que darse para que una medición sea influyente.\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lHHPWLyYMKt"
      },
      "source": [
        "# Modelo lineal múltiple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ayFIHisYMKu"
      },
      "source": [
        "## Expansión del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuugyV9oYMKu"
      },
      "source": [
        "### Analysis of Variace (ANOVA)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMqEq6L4YMKu"
      },
      "source": [
        "El análisis de varianza (o ANOVA) está basado en el hecho de que la siguiente expresión es válida en general para $y$ obtenido a partir modelos de cuadrados mínimos:\n",
        "\n",
        "$$\n",
        "\\underbrace{\\sum_{i=1}^N\\left(t - \\bar{t}\\right)^2}_{SC_\\mathrm{tot}} = \\underbrace{\\sum_{i=1}^N\\left(t - y\\right)^2}_{SC_\\mathrm{res}} + \\underbrace{\\sum_{i=1}^N\\left(y - \\bar{t}\\right)^2}_{SC_\\mathrm{reg}}\\;\\;,\n",
        "$$\n",
        "\n",
        "donde\n",
        "\n",
        "$$\n",
        "\\bar{t} = \\frac{1}{N}\\sum_{j=1}^N t_j\\;\\;,\n",
        "$$\n",
        "\n",
        "puede pensarse como la predicción del modelo más simple que existe: ¡una constante!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duNviICpYMKu"
      },
      "source": [
        "**Nota**: siempre es muy importante tener un modelo de referencia con el que podamos comparar nuestro modelo. En el caso del modelo lineal simple, a menudo se usa el modelo constante aún más simple."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52PtKCrpYMKu"
      },
      "source": [
        "Podemos construir una estadística que, intuitivamente, debería aumentar a medida que aumenta la capacidad del modelo para describir los datos:\n",
        "\n",
        "$$\n",
        "F\\text{-statistic} = \\frac{SC_\\mathrm{reg}}{SC_\\mathrm{res}/(N-2)}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quLXA1urYMKv"
      },
      "source": [
        "Se puede demostrar que, bajo la hipótesis de que el modelo es incorrecto (es decir, que ambos modelos explican bien los datos de manera equivalente), $ F\\text{-statistic}$ sigue una distribución conocida (la distribución F, con 1, y $N -2$ grados de libertad). Grafiquemos esa distribución para nuestro valor de $N$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i29mT6bYMKv"
      },
      "source": [
        "import scipy.stats as st\n",
        "\n",
        "my_f = st.f(dfn=1, dfd=len(t)-2)\n",
        "\n",
        "xx = np.linspace(0, 5, 100)\n",
        "plt.plot(xx, my_f.pdf(xx))\n",
        "plt.xlabel('F-statistic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxH5hXIrYMKv"
      },
      "source": [
        "Ahora, si el valor de $ F \\text{-statistic}$ es muy grande, entonces se puede rechazar la idea de que ambos modelos explican los datos de manera equivalente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVt4PPJeYMKv"
      },
      "source": [
        "x, t, x_plot = make_default_dataset(ground_truth, high_leverage=None)\n",
        "\n",
        "# Ajusto\n",
        "lr = LinearRegression()\n",
        "lr.fit(x.reshape(-1, 1), t)\n",
        "y1 = lr.predict(x.reshape(-1, 1))\n",
        "\n",
        "screg = np.sum((y1 - t.mean())**2)\n",
        "scres = np.sum((t - y1)**2)/(len(t)-2)\n",
        "\n",
        "fratio = screg/scres\n",
        "print('F-statistic = {:.2f} (es decir, ENORME)'.format(fratio))\n",
        "\n",
        "print('La probabilidad de tener un valor de F-statistic al menos así de alto es {:.2e}'.format(1 - my_f.cdf(fratio)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehuxZY7QYMKv"
      },
      "source": [
        "# Let's try now with a degree-two polynomial\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly_feat = PolynomialFeatures(degree=2)\n",
        "xpoly = poly_feat.fit_transform(x.reshape(-1, 1))\n",
        "x_plot2 = poly_feat.transform(x_plot.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC-kpGjwYMKw"
      },
      "source": [
        "xpoly[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Hgw33GYMKw"
      },
      "source": [
        "lr_poly = LinearRegression(fit_intercept=False)\n",
        "\n",
        "lr_poly.fit(xpoly, t)\n",
        "y2 = lr_poly.predict(xpoly)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeFWXvrOYMKw"
      },
      "source": [
        "# Plot datos y gt\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(x, t, 'o', ms=10)\n",
        "plt.plot(x_plot, ground_truth(x_plot), '-', color='0.5', label='Proceso real')\n",
        "plt.xlabel('X', fontsize=16)\n",
        "plt.ylabel('t', fontsize=16)\n",
        "\n",
        "# Ajusto y ploteo ajuste\n",
        "lr = LinearRegression()\n",
        "lr.fit(x.reshape(-1, 1), t)\n",
        "plt.plot(x_plot, lr.predict(x_plot), '-r', lw=4, alpha=0.5, label='Ajuste lineal')\n",
        "plt.plot(x_plot, lr_poly.predict(x_plot2), '-g', lw=4, alpha=0.5, label='Ajuste cuadrático')\n",
        "plt.legend(loc=0, fontsize=16)\n",
        "\n",
        "# Calculo los residuos\n",
        "# res = t - lr.predict(x.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sN_9qWmYMKw"
      },
      "source": [
        "**¿Qué piensan que vamos a obtener del ANOVA en este caso?**\n",
        "\n",
        "Hagámoslo. Pero ahora el modelo de base es el modelo lineal simple, así que la distribución con la que hay que comparar es nuevamente una $F_{1, N-3}$ (porque la diferencia entre ambos modelos es un solo grado de libertad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4RNkgoZYMKw"
      },
      "source": [
        "x, t, x_plot = make_default_dataset(ground_truth, high_leverage=None)\n",
        "\n",
        "# Ajusto\n",
        "lr = LinearRegression()\n",
        "lr.fit(x.reshape(-1, 1), t)\n",
        "y1 = lr.predict(x.reshape(-1, 1))\n",
        "\n",
        "# Compute statistic\n",
        "screg = np.sum((y2 - y1)**2)\n",
        "scres = np.sum((t - y2)**2)/(len(t)-3)\n",
        "fratio = screg/scres\n",
        "\n",
        "my_f = st.f(dfn=1, dfd=len(t) - 3)\n",
        "print('F-statistic = {:.3f} (es decir, NADA)'.format(fratio))\n",
        "print('La probabilidad de tener un valor de F-statistic al menos así de alto es {:.2f}'.format(1 - my_f.cdf(fratio)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm2jBdquYMKx"
      },
      "source": [
        "my_f = st.f(dfn=1, dfd=len(t)-2)\n",
        "plt.plot(xx, my_f.pdf(xx))\n",
        "plt.axvline(fratio, color='k', ls=':')    \n",
        "plt.xlabel('F-statistic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl6BveDgYMKx"
      },
      "source": [
        "**Conclusión**: Como era de esperar, no hay razón para extender nuestro modelo usando ese segundo feature, $x^2$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGxYtcBMYMKx"
      },
      "source": [
        "### Coeficiente de determinación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe9Uz8BdYMKx"
      },
      "source": [
        "Un concepto relacionado es el coeficiente de determinación\n",
        "\n",
        "$$\n",
        "R^2 = \\frac{SC_\\mathrm{tot} - SC_\\mathrm{res}}{SC_\\mathrm{tot}}\\;\\;,\n",
        "$$\n",
        "\n",
        "que toma valores entre 0 y 1, y de alguna manera refleja qué parte de la varianza de los datos es explicada por el modelo. Existe una implementación de esto en `sklearn`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1POTum8YMKx"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "print('R^2 = {:.3f}'.format(r2_score(t, y1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjSJOuDYYMKy"
      },
      "source": [
        "Esto significa que alrededor del 80% de la varianza desaparece con el modelo lineal simple.\n",
        "\n",
        "Una linda propiedad es que $R^2$ es el cuadrado del coeficiente de Pearson entre $X$ y $t$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlA7nDUiYMKy"
      },
      "source": [
        "# Ahora sí! A divertirse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "She7h7q-YMKy"
      },
      "source": [
        "Les proponemos que exploren el dataset de alumnos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g-e_x-7YMKy"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/IAI-UNSAM/datasets/master/students/student-mat.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noiGOFxaYMKz",
        "outputId": "3d3230d2-9dbe-41ba-a050-fa7a298e3cea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 395 entries, 0 to 394\n",
            "Data columns (total 33 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   school      395 non-null    object\n",
            " 1   sex         395 non-null    object\n",
            " 2   age         395 non-null    int64 \n",
            " 3   address     395 non-null    object\n",
            " 4   famsize     395 non-null    object\n",
            " 5   Pstatus     395 non-null    object\n",
            " 6   Medu        395 non-null    int64 \n",
            " 7   Fedu        395 non-null    int64 \n",
            " 8   Mjob        395 non-null    object\n",
            " 9   Fjob        395 non-null    object\n",
            " 10  reason      395 non-null    object\n",
            " 11  guardian    395 non-null    object\n",
            " 12  traveltime  395 non-null    int64 \n",
            " 13  studytime   395 non-null    int64 \n",
            " 14  failures    395 non-null    int64 \n",
            " 15  schoolsup   395 non-null    object\n",
            " 16  famsup      395 non-null    object\n",
            " 17  paid        395 non-null    object\n",
            " 18  activities  395 non-null    object\n",
            " 19  nursery     395 non-null    object\n",
            " 20  higher      395 non-null    object\n",
            " 21  internet    395 non-null    object\n",
            " 22  romantic    395 non-null    object\n",
            " 23  famrel      395 non-null    int64 \n",
            " 24  freetime    395 non-null    int64 \n",
            " 25  goout       395 non-null    int64 \n",
            " 26  Dalc        395 non-null    int64 \n",
            " 27  Walc        395 non-null    int64 \n",
            " 28  health      395 non-null    int64 \n",
            " 29  absences    395 non-null    int64 \n",
            " 30  G1          395 non-null    int64 \n",
            " 31  G2          395 non-null    int64 \n",
            " 32  G3          395 non-null    int64 \n",
            "dtypes: int64(16), object(17)\n",
            "memory usage: 102.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AedVJl54YMKz"
      },
      "source": [
        "Una descripción de cada columna puede encontrarse en la [página de Kaggle](https://www.kaggle.com/uciml/student-alcohol-consumption) de la que sacamos estos datos. \n",
        "\n",
        "* Les proponemos jugar a predecir el valor del examen final ($G3$) en base a cualquiera de lo o los features que tienen a disposición.\n",
        "* Elijan criteriosamente un primer feature y después vayan agregando variables a medida que los datos lo requiran. Para esto último, usen el ANOVA.\n",
        "* Evaluen el modelo mirando los residuos y haciendo plots equivalentes a los que usamos durante este notebook.\n",
        "\n",
        "**Nota**: les dejamos una mini función para hacer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEaVqZxFYMKz"
      },
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "\n",
        "    def anova(t, y_base, y_model, nparam_base, nparam_models):\n",
        "        \"\"\"\n",
        "        Perform simple ANOVA analysis.\n",
        "\n",
        "        :param np.array t: label array (dimensions (nsamples, 1) or (nsamples,))\n",
        "        :param np.array y_base: predictions from base model (dimensions (nsamples, 1) or (nsamples,))\n",
        "        :param np.array y_model: predictions from new (more complex) models (dimensions (nmodels, nsamples)\n",
        "        :param int nparam_base: number of parameters of base model\n",
        "        :param list nparam_models: list with number of parameters of new models\n",
        "        \"\"\"\n",
        "        y_model = np.atleast_2d(y_model)\n",
        "\n",
        "        print('Model\\tdof \\tdiferencia \\tdof \\tF-stat\\t p-value')\n",
        "        print('-----\\t--- \\t---------- \\t--- \\t------\\t -------')\n",
        "        print('Base \\tN-{:d}'.format(nparam_base))\n",
        "\n",
        "        for i, [y, npar] in enumerate(zip(y_model, nparam_models)):\n",
        "            # Compute squared sums\n",
        "            screg = np.sum((y - y_base)**2) / (npar - nparam_base)\n",
        "            scres = np.sum((t - y)**2) / ( len(t) - npar )\n",
        "\n",
        "            fratio = screg/scres\n",
        "\n",
        "            # Define appropiate F distribution\n",
        "            my_f = st.f(dfn=(npar - nparam_base), dfd=(len(t) - npar))\n",
        "            pvalue = 1 - my_f.cdf(fratio)\n",
        "\n",
        "            printdict = {'model': i+1,\n",
        "                         'npar': npar,\n",
        "                         'dpar': npar - nparam_base,\n",
        "                         'fratio': fratio,\n",
        "                         'pvalue': pvalue\n",
        "                         }\n",
        "            # Print line in table\n",
        "            print('New_{model:d} \\tN-{npar:d} \\tNew_{model:d} - Base \\t{dpar:d} '\n",
        "                  '\\t{fratio:.4f}\\t{pvalue:.2e}'.format(**printdict))            \n",
        "        return\n",
        "    \n",
        "else:\n",
        "    from utils import anova"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImWPUlIxYMKz"
      },
      "source": [
        "anova(t, y1, y2, 2, [3,])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BlF0f0AYMKz"
      },
      "source": [
        "**¡Funciona también para muchos modelos!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVpPTxLnYMK0"
      },
      "source": [
        "pp = PolynomialFeatures(degree=5)\n",
        "xp5 = pp.fit_transform(x.reshape(-1, 1))\n",
        "lr.fit(xp5, t)\n",
        "y5 = lr.predict(xp5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT25fhFUYMK0"
      },
      "source": [
        "xp5.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyOvssDMYMK0"
      },
      "source": [
        "anova(t, y1, [y2, y5], 2, [3, 6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvEKOAcZYMK0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}