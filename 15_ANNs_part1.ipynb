{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kedM1-rp-x__"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Introducing the stars\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__, keras.__version__)\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore some basic usages of the `keras` package to build and train ANNs.\n",
    "\n",
    "There are a few different ways in which `keras` can build ANN models. In particular, we will see the Sequential and Functional APIs. For feed-forward fully-connected networks, the Sequential API is probably the more straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Netwoks as good approximators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a model to perform the simple task of approximating a 1-D real function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LknHQn1T-1W4"
   },
   "outputs": [],
   "source": [
    "# Instatiate model\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Use add method to add an input layer (which is also a keras class)\n",
    "model.add(keras.layers.InputLayer(input_shape=(1,)))\n",
    "\n",
    "# Add two fully-connected (a.k.a. Dense) hidden layers\n",
    "# you can change the activation funtion\n",
    "model.add(keras.layers.Dense(5, activation='tanh'))\n",
    "model.add(keras.layers.Dense(4, activation='tanh'))\n",
    "\n",
    "# Add the output layer. As this is a regression problem, choose linear activation\n",
    "model.add(keras.layers.Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use `summary` method to see a description of what we just built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "gnstVI2e_pIS",
    "outputId": "ef2fbad3-22aa-4a8c-f58c-425d3042482b"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "tRUopt6w_qc9",
    "outputId": "3187df29-26b9-4284-d640-7277e99e81c2"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model to run, we must first compile it.\n",
    "\n",
    "At this point, two crucial pieces of information have to be provided:\n",
    "1. The error function (a.k.a. loss function)\n",
    "2. The optimizer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahC-JpkYAkK1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.SGD(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us put our model at test with a simple function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "534XPA2x_sCi",
    "outputId": "db4f9158-5ff6-4290-bea1-1ed8311e377d"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 100)\n",
    "\n",
    "# Modulo\n",
    "t = np.abs(x)\n",
    "\n",
    "# Heavyside\n",
    "# t = np.where(x > 0, 1, 0)\n",
    "\n",
    "plt.plot(x, t, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to fit the model.\n",
    "\n",
    "In its simplest form, the `fit` method takes the input vector `x` (here 1-d) and the label `t` (here 1-d). It also needs a number of `epochs` or steps to perform in the direction of the gradient. \n",
    "\n",
    "**N.B.** In fact, this is the number of times the gradient is evaluated using all data points, but the Stochastic Gradient Descent actually updates the parameter vector for each data batch. Its size can also be provided as an argument to the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4Gskgy3NAzE-",
    "outputId": "f7531f04-915c-4eab-de81-88c84d6c7339"
   },
   "outputs": [],
   "source": [
    "model.fit(x, t, batch_size=int(len(x)/2), epochs=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "sf0K-JzbA083",
    "outputId": "842a22af-c3ba-4728-ae7a-c8ea501cd526"
   },
   "outputs": [],
   "source": [
    "y = model.predict(x)\n",
    "plt.plot(x, t)\n",
    "plt.plot(x, y, 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple network, we can see how things work. Let us get the weights for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_SSTPEe8DnjR"
   },
   "outputs": [],
   "source": [
    "w1, w0 = model.layers[0].get_weights()\n",
    "w2, z0 = model.layers[1].get_weights()\n",
    "w3, z1 = model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights are matrices whose size is related to the size of the layer and the number of units it connects.\n",
    "The second argument is an array with the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "YT3IK5-DGr-L",
    "outputId": "3cb3b527-875d-4c68-f5da-c291d17ea91a"
   },
   "outputs": [],
   "source": [
    "print(w2.shape, z0.shape)\n",
    "print(w2, z0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all this information, we can compute the outcome of the first layer, for each point in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acti(x):\n",
    "    return np.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oR7Ad2cjEvlU"
   },
   "outputs": [],
   "source": [
    "zz = []\n",
    "for i in range(len(w1[0])):\n",
    "  zz.append(acti(w1[0][i] * x + w0[i]))\n",
    "  \n",
    "    # xx = w1[0][i] * x + w0[i]\n",
    "  # yy.append(np.where(xx > 0, xx, 0))\n",
    "\n",
    "zz = np.array(zz).T\n",
    "print(zz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "h-BzHgkGl5xN",
    "outputId": "1e3a3899-e47a-4e07-eb05-eed338c71091"
   },
   "outputs": [],
   "source": [
    "# Compute outcome of second layer\n",
    "yy = acti(np.dot(zz, w2) + z0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "E2_4-ZlEE7i_",
    "outputId": "508ec041-605a-470d-b9b8-a4945cd87ba6"
   },
   "outputs": [],
   "source": [
    "# The final outcome is the combination of each of this four functions, with a weight...\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(x, t, lw=3, label='Ground truth')\n",
    "for i, yi in enumerate(yy.T):\n",
    "  ax.plot(x, yi * w3[i] + z1, '--', label='Unit {}'.format(i+1))\n",
    "\n",
    "ax.plot(x, np.dot(yy, w3) + z1, label='Full result', lw=4, alpha=0.5)\n",
    "ax.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mIOU9XRxGKxx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70jpU79wB8ct"
   },
   "source": [
    "## ANNs take on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to reuse the MNIST dataset of handwritten numbers and train a simple neural network to classify them.\n",
    "\n",
    "The goal is then to try to understand how the network works, so we are going to choose a relatively simple architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "mrZACbJIB9k1",
    "outputId": "0c5735ce-f15c-401d-e123-ee5e9a892c5c"
   },
   "outputs": [],
   "source": [
    "(X_train, t_train), (X_test, t_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels in `t_train` and `t_test` are numbers between 0 and 9.\n",
    "\n",
    "The first thing we do is convert the class labels to 1-of-K encoding. For that we use the function `keras.utils.to_categorical` (similar to `sklearn`'s `OneHotEncoder`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "pQcZTfoSRnpF",
    "outputId": "141e7769-ec81-43d7-f1d5-d8c1c9cec309"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "t_train_ohe = keras.utils.to_categorical(t_train)\n",
    "t_test_ohe = keras.utils.to_categorical(t_test)\n",
    "print(t_train_ohe[:3], t_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we normalise the images. We bring the pixel scale, originally between 0 and 255 to the interval [0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.min(), X_train.max())\n",
    "print(X_test.min(), X_test.max())\n",
    "\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "print(X_train.min(), X_train.max())\n",
    "print(X_test.min(), X_test.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much more to do in terms of data preparation, because `keras` already splits the set in train and test sets (which we will use as validation). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us simply visualize some individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA\n",
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap ='binary', **options)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.figure(figsize=(9,9))\n",
    "plot_digits(X_train[10000:10100], images_per_row=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we start?\n",
    "\n",
    "Let's take some ideas from the source of all knowledge: YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('aircAruvnKk?start=332', width=560, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Let's implement a similar network, but much larger!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5k857OkhCDwp"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "\n",
    "# Twi hidden layers with 32 units each\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "# Output layer. As this is a multi-class classification problem, use K (here 10) units.\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next comes compilation. \n",
    "\n",
    "Because we are using 1-of-K encoding, we need to use `categorical_crossentropy` as loss function. If using digits as labels, the adequate function is `sparse_categorical_crossentropy`.\n",
    "\n",
    "We also tell the model to monitor the Accuracy (but we could provide other metrics here, such as the recall of fives... `keras.metrics.Recall()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "boBes4cbCRqG"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy', keras.metrics.Recall(class_id=5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Small game**: Can you compute the number of parameters in this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "Ketw0YRzDbya",
    "outputId": "7343f00b-2156-40b9-f39f-61fdd7b42dc4"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training can be tricky, even for a small network such as this. \n",
    "\n",
    "To accelerate the process, and check that the network is not overfitting, we will add an additional step in the fitting process. A _callback_ that can stop the training early if no improvement in the validation loss is seen.\n",
    "\n",
    "This is implemented in `EarlyStopping`. Let's set it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = keras.callbacks.EarlyStopping(patience=15, monitor='val_loss',\n",
    "                                      restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we wait 15 epochs to see an improvement. If none is seen, the fit is returned to the optimal values and the training is stopped. This is _very_ useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know fit the model, but notice the following changes:\n",
    "\n",
    "1. The output of the method is stored in a variable `history` that contains the evolution of the traning process.\n",
    "2. We add the argument `validation_data` to define what dataset to use for validation.\n",
    "3. We include a callback (there could be legion, see `keras.callbacks` and [documentation](https://keras.io/api/callbacks/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bpzbw3cBDdUg",
    "outputId": "0cbf3241-726c-4e70-e96c-e9825c204822"
   },
   "outputs": [],
   "source": [
    "history = model.fit(epochs=100, x=X_train, y=t_train_ohe, validation_data=(X_test, t_test_ohe), \n",
    "                    callbacks=[early,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nice, but we would like to see a plot of this. This is what `history` is all about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "-GOxGU5ZEw1b",
    "outputId": "1b47ed80-7834-4cc2-fc6a-e3520d96e126"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mZu1Doa3WyS"
   },
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploremos ahora un poco más los errores de la red. Para eso, trabajaremos con el conjunto de test (esto no es del todo correcto porque usé el mismo conjunto para hacer la validación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, t_test_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a closer look at the cases in which the network made mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "3Ri5dGJm0GOU",
    "outputId": "a5b8cbe9-a8f8-4e59-c35f-53556eb03adc"
   },
   "outputs": [],
   "source": [
    "# Compute predictions and find instances with error\n",
    "y_test = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# Find errors\n",
    "ierror = (y_test - t_test != 0)\n",
    "\n",
    "# How many are there\n",
    "print('There are {} errors in the validation set'.format(np.sum(ierror)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "Stfm0aes022Y",
    "outputId": "6be87073-3542-45fc-ad76-504f699f1c9d"
   },
   "outputs": [],
   "source": [
    "n_images = 18\n",
    "n_columns = 8\n",
    "\n",
    "n_rows = np.int(n_images / n_columns)\n",
    "\n",
    "if n_images % n_columns != 0:\n",
    "    n_rows += 1\n",
    "\n",
    "fig, axs = plt.subplots(ncols=n_columns, nrows=n_rows, figsize=(12, 2*n_rows))\n",
    "# Veamos algunos ejemplos de los datos en los que se equivocó\n",
    "\n",
    "for i, ax in zip(range(n_images), axs.flatten()):\n",
    "    ax.imshow(X_test[ierror][i], interpolation='None', cmap='binary')\n",
    "    ax.set_title('Prediction: {}\\nTruth: {}'.format(y_test[ierror][i], t_test[ierror][i]))\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tO9aq05w35Mp"
   },
   "source": [
    "Ok, this seems reasonable, right? I mean, look at those numbers. Some are really tough...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the probability distribution. I keep the probability of the class that was chosen by the network, both in the case of errors and those that were not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "xf4nKE6wwCRz",
    "outputId": "fb8fda06-acb9-4b6e-a1fb-b529bd4dd3f0"
   },
   "outputs": [],
   "source": [
    "pred_proba_all = np.max(model.predict(X_test), axis=1)\n",
    "\n",
    "pred_proba = np.max(model.predict(X_test[~ierror]), axis=1)\n",
    "pred_proba_err = np.max(model.predict(X_test[ierror]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos la distribución\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "bins = np.linspace(0, 1, 50)\n",
    "plt.hist(pred_proba, bins=bins, histtype='step', label='Correct', density=True, log=True)\n",
    "plt.hist(pred_proba_err, bins=bins, histtype='step', label='Error', density=True)\n",
    "\n",
    "# Labels and ticks\n",
    "plt.xlabel('Probability', size=14)\n",
    "plt.gca().tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good. The network seems to be less sure when making mistakes. This means we could tweak the decision threshold a bit to improve the performance.\n",
    "\n",
    "But it seems to be quite sure of cases in which it makes mistakes. Let's see those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = (pred_proba_all > 0.95) * (y_test - t_test != 0)\n",
    "\n",
    "print('There are {} images mistakenly classified with over 95% probability'.format(sum(ii)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 18\n",
    "n_columns = 8\n",
    "\n",
    "n_rows = np.int(n_images / n_columns)\n",
    "\n",
    "if n_images % n_columns != 0:\n",
    "    n_rows += 1\n",
    "\n",
    "fig, axs = plt.subplots(ncols=n_columns, nrows=n_rows, figsize=(12, 2*n_rows))\n",
    "# Veamos algunos ejemplos de los datos en los que se equivocó\n",
    "\n",
    "for i, ax in zip(range(n_images), axs.flatten()):\n",
    "    ax.imshow(X_test[ii][i], interpolation='None', cmap='binary')\n",
    "    ax.set_title('Prediction: {}\\nTruth: {}'.format(y_test[ii][i], \n",
    "                                                    t_test[ii][i]))\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the network learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to look inside the network to understand if he understood something about what numbers are like or not. There are many parameters, but we are hopeful that at least the first layer is something reasonable, like an edge detector. Let's see.\n",
    "\n",
    "Let's read the weights and bias of the first hidden layer and see the shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvJjmOQ6VJ3B"
   },
   "outputs": [],
   "source": [
    "# Note here the relevant layer is layer[1], as layer[0] is a flattening layer.\n",
    "W, b = model.layers[1].get_weights()\n",
    "print(W.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 847
    },
    "id": "X4WcRMSGpulN",
    "outputId": "37b444f4-257c-426e-90b0-6cc6ac311dfe"
   },
   "outputs": [],
   "source": [
    "WW = W.reshape([28,28,32])\n",
    "\n",
    "# Find relavant limits for pixel values\n",
    "Wmin = WW[3:-3, 3:-3].min()\n",
    "Wmax = WW[3:-3, 3:-3].max()\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for i in range(WW.shape[-1]):\n",
    "    ax = fig.add_subplot(6, 6, i+1)\n",
    "    #  ax.imshow(WW[2:-2, 2:-2, i], interpolation='None')\n",
    "    # Fixed limits in Z axis\n",
    "    \n",
    "    ax.imshow(WW[:, :, i], interpolation='None', vmin=Wmin, vmax=Wmax)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights of the first layer do not look at all like border detectors, or anything like that. \n",
    "\n",
    "It seems the network finds a much stranger way to generalise than we would do. We will see that CNNs do something much closer to what one would expect.\n",
    "\n",
    "**Does this make sense?**\n",
    "\n",
    "* We never provided any idea of neighbourhood between features. How could the network tell?\n",
    "* How can we generate a neural network that recognizes images in a more similar way to how humans do?\n",
    "\n",
    "This is the topic of the week after the next..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can you improve the performance of this network without changing the architecture?\n",
    "    * Try one of the reduction procedures from a few weeks ago (PCA, etc.)\n",
    "    * Add an additional callback to regulate the learning rate of the SGD algorithm (algorithmic-centric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IntroRN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
